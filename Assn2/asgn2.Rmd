---
title: "INFO304 Assignment 2 2022"
author: "Ethan Smith - 5652106"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(dev = 'png') # make images smaller resolution in pdf
source("logistic.R", local = knitr::knit_global())
source("mice.R", local = knitr::knit_global())
source("rf.R", local = knitr::knit_global())
source("utils.R", local = knitr::knit_global())
```

## QUESTION ONE (10 MARKS)

Visualise the patterns of missing data for hepatitis.data and briefly comment on the patterns
you observe. 

```{r, warning=FALSE}
library(naniar)
library(ggplot2)
Hep <- read.csv("hepatitis.data")
gg_miss_var(Hep,show_pct=TRUE)  
gg_miss_upset(Hep,nsets=ncol(Hep),nintersects=NA)
vis_miss(Hep)
```

Here we can see that within the entire dataset 5.4% of the values are missing. By summing the counts of each observation with NA values from the 2nd plot there are 75 observations in the dataset that are missing at least one value for a predictor (just under 50% of all observations). The three variables which are missing the most values are protime, alkphosphate and albumin. From the 2nd plot we can also see that combinations of these variables are also the most likely to be missing in comparison to other variables. 

I researched into these variables and found they are all found in blood so within this sample there may have been an issue around obtaining results from blood tests of patients. The biggest concern here is for the protime predictor variable which has not been recorded for almost half the observations in the dataset. Even with methods such as imputation to help predict values for missing data this variable should be treated very carefully as there is no certainity these value will be representative of the true distribution. 

It appears overall that medically based measurements that will be more unique to a patient are more likely to be missing than basic patient information but the majority of them have a small proportion of missing values that should be reasonable to account for.

\newpage

## QUESTION TWO (10 MARKS)

Justify why the explanatory variable “Sex” should be removed from the data prior to
modelling. 


```{r, warning=FALSE}
t <- table(Hep$Class, Hep$Sex)
colnames(t) = c("Male", "Female")
rownames(t) = c("Died", "Lived")
t
```

From this table between class and sex it can be shown that sex is irrelevant for predicting whether a patient lives or dies. Overall we can see that the probability of surviving is much higher than the probability of dying, as this is combined with a very unbalanced level of males and females in the dataset it has given a set of results where all of the female patients survived and therefore there is nothing associated with a female patient dying. 

Due to the imbalance between males and females in the dataset this could also cause another issue where if a random train test split is made it is possible that no females could be included in a possible training set which would cause errors for prediction. Both issues would have been likely to not exist if a larger sample of females was included but with the observations given it is clear sex should be removed as a predictor.

\newpage

## QUESTION THREE (45 MARKS) - Logistic Regression 

Perform the following steps
3.1 Load in the hepatitis data.


```{r, warning=FALSE}
hep <- read.csv("hepatitis.data")
```

3.2 Turn the response and appropriate explanatories into factors and remove the “Sex”
column. 

```{r, warning=FALSE}
hep <- data.factorise(hep, c(1,3:14,20))
hep <- hep[,-3]
```

3.3 Create an imputed dataset for the hepatitis data using the default values. 

```{r, warning=FALSE}
hep.imp <- make.imputations(hep, 1)
```


3.4 Estimate the accuracy of a logistic model using all explanatories (Class ~ .) by running
test.logistic(…) 100 times – present the result as a boxplot. Hint: Use replicate(…).
Comment on the accuracy versus that stated in the Breiman and Diaconis/Efron paper.
Why might your result differ from the published examples? 


```{r, warning=FALSE}
logistic <- replicate(100, test.logistic(hep.imp, Class ~.))
boxplot(logistic, main = "Logistic regression performance on 100 tests", ylab = "Accuracy")
```


3.5 Breiman suggests that variable importance can be based on examining the absolute value
of the coefficients of a variable divided by their standard deviation (over many runs of
the model with different training sets). Using glm.coefficients(imp,formula,perc.train=0.9)
do 100 runs of this function, produce the variable importance measure stated above, and
create a barplot showing variable importance for each explanatory.


How stable is this measure? Rerun the model several times and comment on your
observations. What might this suggest about model stability and logistic regression for the
hepatitis dataset? Would you be confident in using this approach to assess which variables
are important?



```{r, warning=FALSE}
library(matrixStats)
par(mfrow = c(3,2))
for (var in 1:6) {
  importance <-as.data.frame(abs(replicate(100, glm.coefficients(hep.imp, Class ~.)))) 
  importance <- importance[-1,]
  importance <- as.data.frame(rowMeans(importance))
  importance <- as.data.frame(importance$`rowMeans(importance)` / importance_sd$sd)
  overall <- cbind(overall, importance)
  colnames(importance) <- "Value"
  barplot(importance$Value, main = "Variable importance (Breiman)", 
          xlab = "variables", ylab = "Importance", 
          names.arg = rownames(importance), cex.names = 0.7,
          ylim = c(0, max(importance) + 0.2))
}

overall <- data.frame(ncol = 18)
for (var in 1:50) {
  importance <-as.data.frame(abs(replicate(100, glm.coefficients(hep.imp, Class ~.)))) 
  importance <- importance[-1,]
  importance <- as.data.frame(rowMeans(importance))
  importance <- as.data.frame(importance$`rowMeans(importance)` / importance_sd$sd)
  overall <- cbind(overall, importance)
}

overall <- overall[,-1]
mean <- rowMeans(overall)
sd <- rowSds(as.matrix(overall))
vari <- rowVars(as.matrix(overall))
par(mfrow = c(3,1))
barplot(mean, names.arg = rownames(importance), cex.names = 0.7,
        main = "Mean variable importance")
barplot(sd, names.arg = rownames(importance), cex.names = 0.7,
        main = "SD of importance")
barplot(vari, names.arg = rownames(importance), cex.names = 0.7,
        main = "Variation of importance")
```


3.6 Implement variable importance using permutation for the logistic model and examine
the stability using this approach. HINT: The function definition variable.importance(…)
has been provided but is empty. You need to write this function, which uses
permutation of one explanatory column to estimate the percentage increase in error
when the variable relationship in the data has been removed. There is a function
provided (collect.var.imp(..)) that collects up the results for all explanatories.


In your writeup include your function code for variable.importance(…), the resulting
visualisation of the model, evidence of stability (or lack of it), and a discussion that
addresses:

  Is the stability improved over the approach in part 3.5?
  
  Which variables appear to be important? How do these compare with
  the provided literature? NOTE: Be aware that you have removed one
  column so the Breiman paper (which just uses column numbers)
  needs to be interpreted with care. 



```{r, warning=FALSE}
par(mfrow = c(3,2))
for (var in 1:6) {
  percent <- collect.var.imp(hep.imp, Class ~.)
  percent <- colMeans(percent)
  barplot(percent, names.arg = rownames(importance), cex.names = 0.7, 
          ylim = c(-1, max(percent) + 1), 
          xlab = "variable", ylab = "Error increase (%)", 
          main = "Variable importance by permutation")
}

overall <- data.frame(ncol = 18)
for (var in 1:50) {
    percent <- collect.var.imp(hep.imp, Class ~.)
  percent <- colMeans(percent)
  overall <- cbind(overall, percent)
}
overall <- overall[,-1]
mean <- rowMeans(overall)
sd <- rowSds(as.matrix(overall))
vari <- rowVars(as.matrix(overall))
par(mfrow = c(3,1))
barplot(mean, names.arg = rownames(importance), cex.names = 0.7,
        main = "Mean variable importance")
barplot(sd, names.arg = rownames(importance), cex.names = 0.7,
        main = "SD of importance")
barplot(vari, names.arg = rownames(importance), cex.names = 0.7,
        main = "Variation of importance")
```


## QUESTION FOUR (20 Marks) – Decision Trees and Random Forests


4.1 Implement a decision tree (using the default parameters) to predict Class using the
imputed data (note that you want to predict the response as a “class”) and compare this to
the logistic model. Include in your writeup the function (code) that does the decision tree
and a boxplot showing the resulting error (x100 runs) and compare this to the logistic
regression result. You should also compare the 2 distributions and the mean/sd as further
evidence of their similarity/difference. 


```{r, warning=FALSE}
num <- sample.int(999, 1)
set.seed(num)

logistic <- replicate(100, test.logistic(hep.imp, Class ~.))
dt <- replicate(100, test.dt(hep.imp, Class ~.))

par(mfrow = c(1,2))
boxplot(logistic, main = "logistic accuracy", ylim = c(0.5,1.0))
boxplot(dt, main = "Dt accuracy", ylim = c(0.5,1.0))

mean(dt)
mean(logistic)
sd(dt)
sd(logistic)

t.test(logistic, dt)
```


4.2 Examine the provided code for a random forest in rf.R– This is a simple implementation:
the predict.rf(..) function takes an imputed list of datasets, and builds a random forest and does the prediction and returns the accuracy measure (for direct comparison with previous models).

Give a brief description of how the random forest is created and tested.
Run the supplied code and compare the resulting accuracy against the logistic model and
single decision tree. Use replicate to run test.rf(…) 100 times with ntrees=1, 5, 10 and 20.

Leave the other parameters at their default value. Does the performance improve? Briefly
explain why this model seems superior (does it?) to logistic regression and a single decision tree. 



```{r, warning=FALSE}
par(mfrow = c(2,2))
for (var in 1:4) {
  num <- sample.int(999, 1)
  set.seed(num)
  logistic <- replicate(100, test.logistic(hep.imp, Class ~.))
  dt <- replicate(100, test.dt(hep.imp, Class ~.))
  rf1 <- replicate(100, test.rf(hep.imp, Class ~., ntrees = 1))
  rf5 <- replicate(100, test.rf(hep.imp, Class ~., ntrees = 5))
  rf10 <- replicate(100, test.rf(hep.imp, Class ~., ntrees = 10))
  rf20 <- replicate(100, test.rf(hep.imp, Class ~., ntrees = 20))
  
  
  results = data.frame(rf1, rf5, rf10, rf20, logistic, dt)
  boxplot(results, main = "Model accuracy scores", xlab = "models", 
          ylab = "Accuracy", names = colnames(results), las = 2)
}
```




## QUESTION FIVE (15 MARKS) – Write approx. 300 words 


Assume you are given a dataset from a loans company that describes the following
characteristics of customers including whether they were found to be a good or bad credit
risk (the response): 


Age of customer;
Experience: professional experience in years;
Income of customer;
Average monthly credit card spending;
Mortgage: size of mortgage;
Credit Card: No/Yes;
Educational level: three categories (undergraduate, graduate, professional);
Credit Risk: Good/Bad 


You are ultimately interested in building a model that predicts Credit Risk given the other
independent (explanatory) variables.


Explain the steps that you would follow to understand the patterns in the dataset, PRIOR to
building a model for prediction. Ensure in your description that you include comments on
what information each method or visualisation gives, and why this may be important prior
to modelling the data. 
